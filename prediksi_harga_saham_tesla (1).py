# -*- coding: utf-8 -*-
"""Prediksi Harga Saham Tesla.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16E5nChNwM9XODlcxTLhYwUWhsA1ABI1-

# Proyek Pertama: Predictive Analytics Saham Tesla (2010-2023)
Pendahuluan
Penjelasan Proyek: Notebook ini bertujuan untuk memprediksi harga saham Tesla (2010-2023) menggunakan teknik Predictive Analytics berbasis model Long Short-Term Memory (LSTM). Model ini dirancang untuk memanfaatkan data historis harga saham guna memprediksi harga di masa depan. Notebook ini mencakup berbagai tahap mulai dari eksplorasi data hingga evaluasi model.

Data set: https://www.kaggle.com/datasets/muhammadbilalhaneef/-tesla-stock-price-from-2010-to-2023?resource=download

## 1. Import Library
Pada bagian ini, kita mengimpor berbagai pustaka Python yang diperlukan untuk analisis data, visualisasi, machine learning, dan pembangunan model. Library seperti numpy, pandas, dan matplotlib digunakan untuk manipulasi data dan visualisasi. Library tensorflow.keras digunakan untuk membangun model LSTM.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import LinearRegression
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
import warnings

warnings.filterwarnings('ignore')

"""## 2. Load Dataset
Kita memuat dataset saham Tesla dari file CSV menggunakan pd.read_csv(). Setelah itu, kita memeriksa beberapa data teratas dengan df.head() untuk memahami struktur awal data.
"""

df = pd.read_csv("https://raw.githubusercontent.com/Adri720S/PredictiveAnalytics1_Saham-Tesla-2010-2023-/refs/heads/main/Tesla%20Stock%20Price%20(2010%20to%202023).csv")
df.head()

"""## 3. Data Understanding

#### a. Dimensi Dataset: "Kita memeriksa jumlah baris dan kolom dalam dataset menggunakan properti .shape."
"""

# Dimensi dataset
print(f"Dataset memiliki {df.shape[0]} baris dan {df.shape[1]} kolom.")

"""#### b. Tipe Data: "Informasi tentang tipe data tiap kolom diperiksa menggunakan df.info() untuk memastikan kompatibilitas dengan analisis selanjutnya."

"""

# Informasi tipe data
df.info()

"""#### c. Statistik Deskriptif: "Melakukan ringkasan statistik numerik menggunakan .describe() untuk melihat distribusi data."""

# Statistik deskriptif
df.describe()

"""#### d. Ubah kolom Date ke Format Datetime"""

# Mengubah kolom Date menjadi datetime
df['Date'] = pd.to_datetime(df['Date'])
# Informasi tipe data
df.info()

"""#### e. Visualisasi Data
Pergerakan harga penutupan saham Tesla divisualisasikan menggunakan line plot. Ini memberikan gambaran umum tentang pola harga saham selama periode waktu tertentu.
"""

plt.figure(figsize=(14, 7))
plt.plot(df['Date'], df['Close'], label='Harga Penutupan')
plt.title('Pergerakan Harga Saham Tesla (2010-2023)')
plt.xlabel('Tahun')
plt.ylabel('Harga Penutupan')
plt.legend()
plt.show()

"""## 4. Data Preparation

#### a. Missing Values
Kita memeriksa apakah ada data yang hilang (missing values) di setiap kolom. Jika ada, metode forward fill digunakan untuk mengisi nilai yang hilang agar data tetap konsisten.
"""

# Mengecek missing values
print("Jumlah missing values:")
print(df.isnull().sum())

# Mengisi missing values dengan metode forward fill
df.fillna(method='ffill', inplace=True)

"""#### b. Duplicate Data
Data duplikat diidentifikasi menggunakan df.duplicated().sum(). Jika ada duplikasi, kita menghapusnya dengan .drop_duplicates().
"""

# Mengecek duplikasi
duplicates = df.duplicated().sum()
print(f"Terdapat {duplicates} data duplikat.")

# Jika ada, menghapus duplikasi
df = df.drop_duplicates()

"""#### c. Normalisasi Data
Kolom Close dinormalisasi menggunakan MinMaxScaler agar nilainya berada dalam rentang 0-1. Ini bertujuan untuk meningkatkan performa model yang sensitif terhadap skala data.
"""

# Normalisasi data kolom Close
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(df[['Close']])

# Menampilkan data yang telah dinormalisasi
scaled_data[:5]

"""#### d. Membuat Sequence Data
Kita membuat sequence data dengan panjang 60 untuk digunakan sebagai input model LSTM. Panjang ini berarti model akan menggunakan data harga penutupan 60 hari terakhir untuk memprediksi harga pada hari berikutnya.
"""

# Fungsi untuk membuat sequence data
def create_sequences(data, seq_length):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i + seq_length, 0])
        y.append(data[i + seq_length, 0])
    return np.array(X), np.array(y)

# Parameter panjang sequence
seq_length = 60

# Membuat sequence data
X, y = create_sequences(scaled_data, seq_length)

# Melihat dimensi data hasil sequence
print(f"Dimensi X: {X.shape}, Dimensi y: {y.shape}")

"""## 5. Preprocessing Data
#### a. Split Data
Dataset dibagi menjadi subset training (80%) dan testing (20%).
"""

data = df[['Close']]
scaled_data = scaler.fit_transform(data)
train_size = int(len(scaled_data) * 0.8)
train_data = scaled_data[:train_size]
test_data = scaled_data[train_size:]

"""#### b. Buat Sequence untuk Training dan Testing
Sequence data dibuat dari subset training dan testing.
"""

X_train, y_train = create_sequences(train_data, seq_length)
X_test, y_test = create_sequences(test_data, seq_length)

X_train = X_train.reshape(-1, seq_length, 1)
X_test = X_test.reshape(-1, seq_length, 1)

"""## 6. Bangun Model LSTM
Kita membangun model LSTM menggunakan Sequential dari tensorflow.keras. Model ini memiliki dua lapisan LSTM dengan lapisan dropout untuk mencegah overfitting, serta dua lapisan Dense untuk menghasilkan output akhir berupa prediksi harga.
"""

# Bangun model LSTM
model = Sequential([
    LSTM(50, return_sequences=True, input_shape=(seq_length, 1)),
    Dropout(0.2),
    LSTM(50, return_sequences=False),
    Dropout(0.2),
    Dense(25),
    Dense(1)
])

# Compile model
model.compile(optimizer='adam', loss='mean_squared_error')

# Latih model
history = model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test))

"""## 7. Evaluasi dan Prediksi
Kita mengevaluasi performa model dengan menghitung Root Mean Squared Error (RMSE), yang memberikan metrik seberapa baik model dapat memprediksi harga saham dibandingkan data aktual.
"""

# Prediksi menggunakan data testing
predictions = model.predict(X_test)
predictions = scaler.inverse_transform(predictions)  # Balikkan skala ke bentuk asli

# Balikkan skala y_test ke bentuk asli
y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))

# Evaluasi dengan RMSE
from sklearn.metrics import mean_squared_error
rmse = np.sqrt(mean_squared_error(y_test_actual, predictions))
print(f'Root Mean Squared Error (RMSE): {rmse}')

"""## 8. Visualisasi Hasil
Hasil prediksi dibandingkan dengan harga aktual menggunakan grafik untuk melihat sejauh mana model mampu mengikuti pola harga saham.
"""

plt.figure(figsize=(14, 7))
plt.plot(df['Date'][-len(y_test):], y_test_actual, label='Harga Aktual')
plt.plot(df['Date'][-len(y_test):], predictions, label='Harga Prediksi')
plt.title('Prediksi Harga Saham Tesla')
plt.xlabel('Tanggal')
plt.ylabel('Harga Penutupan')
plt.legend()
plt.show()