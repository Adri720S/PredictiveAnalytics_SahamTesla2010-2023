# -*- coding: utf-8 -*-
"""Prediksi_Harga_Saham_Tesla (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bQ6JkuD8R0iwKCLruKF4CvXq-8KnalOl

# Proyek Pertama: Predictive Analytics Saham Tesla (2010-2023)
Pendahuluan
Penjelasan Proyek: Notebook ini bertujuan untuk memprediksi harga saham Tesla (2010-2023) menggunakan teknik Predictive Analytics berbasis model Long Short-Term Memory (LSTM). Model ini dirancang untuk memanfaatkan data historis harga saham guna memprediksi harga di masa depan.

Data set: https://www.kaggle.com/datasets/muhammadbilalhaneef/-tesla-stock-price-from-2010-to-2023?resource=download

## 1. Import Library
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import LinearRegression
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
import warnings

warnings.filterwarnings('ignore')

"""## 2. Load Dataset

"""

df = pd.read_csv("https://raw.githubusercontent.com/Adri720S/PredictiveAnalytics1_Saham-Tesla-2010-2023-/refs/heads/main/Tesla%20Stock%20Price%20(2010%20to%202023).csv")
df.head()

"""## 3. Data Understanding

#### a. Dimensi Dataset: "Memeriksa jumlah baris dan kolom dalam dataset menggunakan properti .shape."
"""

# Dimensi dataset
print(f"Dataset memiliki {df.shape[0]} baris dan {df.shape[1]} kolom.")

"""#### b. Tipe Data: "Informasi tentang tipe data tiap kolom diperiksa menggunakan df.info() untuk memastikan kompatibilitas dengan analisis selanjutnya."

"""

# Informasi tipe data
df.info()

"""#### c. Penanganan Missing Values
Penanganan missing value dengan metode forward fill untuk mengisi nilai yang hilang agar data tetap konsisten.
"""

# Mengecek missing values
print("Jumlah missing values:")
print(df.isnull().sum())

# Mengisi missing values dengan metode forward fill
df.fillna(method='ffill', inplace=True)

"""#### d. Duplicate Data"""

# Mengecek duplikasi
duplicates = df.duplicated().sum()
print(f"Terdapat {duplicates} data duplikat.")

# Jika ada, menghapus duplikasi
df = df.drop_duplicates()

"""#### e. Statistik Deskriptif: "Melakukan ringkasan statistik numerik menggunakan .describe() untuk melihat distribusi data."""

# Statistik deskriptif
df.describe()

"""#### f. Mendeteksi outlier"""

# Deteksi Outlier menggunakan IQR
def detect_outliers_iqr(column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]
    return outliers

# Deteksi outlier untuk semua kolom numerik
numerical_cols = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']
for col in numerical_cols:
    outliers = detect_outliers_iqr(col)
    print(f"\nJumlah Outlier pada kolom {col}: {len(outliers)}")

# Visualisasi distribusi dan outlier
plt.figure(figsize=(10, 6))
for i, col in enumerate(numerical_cols, 1):
    plt.subplot(2, 3, i)
    sns.boxplot(x=df[col])
    plt.title(f"Boxplot {col}")
plt.tight_layout()
plt.show()

"""Informasi kondisi dataset tidak ada missing value, tidak ada data duplikat dan outlier merupakan nilai dari pergerakan saham tersebut.

## 4. Data Preparation

#### a. Ubah kolom Date ke Format Datetime
"""

# Mengubah kolom Date menjadi datetime
df['Date'] = pd.to_datetime(df['Date'])
# Informasi tipe data
df.info()

"""#### b. Normalisasi Data
Kolom Close dinormalisasi menggunakan MinMaxScaler agar nilainya berada dalam rentang 0-1. Bertujuan untuk meningkatkan performa model yang sensitif terhadap skala data.
"""

# Normalisasi data kolom Close
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(df[['Close']])

# Menampilkan data yang telah dinormalisasi
scaled_data[:5]

"""#### c. Split Data
Dataset dibagi menjadi subset training (80%) dan testing (20%).
"""

data = df[['Close']]
scaled_data = scaler.fit_transform(data)
train_size = int(len(scaled_data) * 0.8)
train_data = scaled_data[:train_size]
test_data = scaled_data[train_size:]

"""#### d. Membuat Sequence Data
Membuat sequence data dengan panjang 60 untuk digunakan sebagai input model LSTM. Maka model akan menggunakan data harga penutupan 60 hari terakhir untuk memprediksi harga pada hari berikutnya.
"""

# Fungsi untuk membuat sequence data
def create_sequences(data, seq_length):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i + seq_length, 0])
        y.append(data[i + seq_length, 0])
    return np.array(X), np.array(y)

# Parameter panjang sequence
seq_length = 60

# Membuat sequence data
X, y = create_sequences(scaled_data, seq_length)

# Melihat dimensi data hasil sequence
print(f"Dimensi X: {X.shape}, Dimensi y: {y.shape}")

"""#### e. Visualisasi Data
Pergerakan harga penutupan saham Tesla divisualisasikan menggunakan line plot. Agar gambaran umum tentang pola harga saham selama periode waktu tertentu dapat terlihat.
"""

plt.figure(figsize=(14, 7))
plt.plot(df['Date'], df['Close'], label='Harga Penutupan')
plt.title('Pergerakan Harga Saham Tesla (2010-2023)')
plt.xlabel('Tahun')
plt.ylabel('Harga Penutupan')
plt.legend()
plt.show()

"""## 5. Preprocessing Data

#### Membuat Sequence untuk Training dan Testing
"""

X_train, y_train = create_sequences(train_data, seq_length)
X_test, y_test = create_sequences(test_data, seq_length)

X_train = X_train.reshape(-1, seq_length, 1)
X_test = X_test.reshape(-1, seq_length, 1)

"""## 6. Bangun Model LSTM
Membangun model LSTM menggunakan Sequential dari tensorflow.keras. Menggunakan dua lapisan LSTM dengan lapisan dropout untuk mencegah overfitting, serta dua lapisan Dense untuk menghasilkan output akhir berupa prediksi harga.
"""

# Bangun model LSTM
model = Sequential([
    LSTM(50, return_sequences=True, input_shape=(seq_length, 1)),
    Dropout(0.2),
    LSTM(50, return_sequences=False),
    Dropout(0.2),
    Dense(25),
    Dense(1)
])

# Compile model
model.compile(optimizer='adam', loss='mean_squared_error')

# Latih model
history = model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test))

"""## 7. Evaluasi dan Prediksi"""

# Prediksi menggunakan data testing
predictions = model.predict(X_test)
predictions = scaler.inverse_transform(predictions)  # Balikkan skala ke bentuk asli

# Balikkan skala y_test ke bentuk asli
y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))

# Evaluasi dengan RMSE
from sklearn.metrics import mean_squared_error
rmse = np.sqrt(mean_squared_error(y_test_actual, predictions))
print(f'Root Mean Squared Error (RMSE): {rmse}')

"""## 8. Visualisasi Hasil
Hasil prediksi dibandingkan dengan harga aktual menggunakan grafik untuk melihat sejauh mana model mampu mengikuti pola harga saham.
"""

plt.figure(figsize=(14, 7))
plt.plot(df['Date'][-len(y_test):], y_test_actual, label='Harga Aktual')
plt.plot(df['Date'][-len(y_test):], predictions, label='Harga Prediksi')
plt.title('Prediksi Harga Saham Tesla')
plt.xlabel('Tanggal')
plt.ylabel('Harga Penutupan')
plt.legend()
plt.show()